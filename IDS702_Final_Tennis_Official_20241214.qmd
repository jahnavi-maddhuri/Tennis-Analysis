---
title: "Study of tennis athletes performance on different surfaces and factors that affect wins"
author: 
  - "Alejandro Paredes La Torre, Liangcheng (Jay) Liu"
  - "Nzarama Michaella Desire Kouadio, Jahnavi Maddhuri"
subtitle: "2024-12-15"
format: pdf
header-includes:
      - \usepackage{float}
      - \usepackage{authblk}
      - \floatplacement{table}{H}
execute:
  echo: false
geometry: margin=0.8in
---

## Abstract

Modeling key factors that influence professional tennis matches is essential for athletes and teams to address underdeveloped areas and for researchers to enhance the development of young and amateur players. This study uses ATP data to examine the effects of player rankings and aces on match outcomes. It explores how ranking differences impact match duration and investigates the relationship between the number of aces a player hits and their odds of winning. Through exploratory data analysis and regression modeling, the findings reveal that larger ranking gaps lead to shorter matches, though surface types and match conditions also play a role. Additionally, hitting more aces significantly improves a player’s chances of winning, with surface types like clay and hard courts influencing this relationship.

## Introduction

Predicting outcomes in sports has long been a central focus for athletes, teams, and industries alike. Statistical science, when applied to sports, plays a pivotal role in optimizing an athlete’s performance, making it a subject of significant interest for both researchers and commercial enterprises. In professional tennis, analyzing the factors that influence match outcomes offers insights that extend beyond simple predictions, encompassing strategic advancements and broader applications.

Such insights have practical implications for refining rankings (Klaassen and Magnus, 2003)[16], ratings (Kovalchik, 2016)[17], and seedings(Boulier et. al 1999)[15], serving as a foundation for performance analysis and strategy optimization. Predictive models are pivotal in industries like sports betting, where they drive decision-making and risk management (Foley-Train, 2014)[18]. . In academic research, these models contribute to methodological improvements, as seen in the work of Štrumbelj & Vračar (2012)[6], who explored probabilistic approaches to predicting match outcomes. 

Analyzing professional tennis data bridges practical applications and theoretical advancements. Studies like those by Boulier and Stekler (1999)[7], Lasek, Szlávik, and Bhulai (2013) [8], and McHale and Davies (2007)[9] highlight how data-driven approaches can uncover nuanced patterns in sports, offering a deeper understanding of the game and its predictive dynamics

A growing body of literature underscores the role of data-driven approaches in uncovering intricate patterns within tennis. For instance, Boulier and Stekler (1999)[7] demonstrated how statistical models could be used to assess player performance, while Lasek, Szlávik, and Bhulai (2013)[8] examined predictive methods for ranking systems. McHale and Davies (2007)[9] explored the influence of match dynamics on outcomes, further bridging theoretical advancements with practical applications.

Early foundational studies, such as those by Newton and Keller (2005)\[2\], O'Malley (2008)\[3\], and Riddle (1988)\[4\], established that under the assumption of independent and identically distributed (iid) point outcomes on a player's serve, the probability of winning a match could be derived from serve-point probabilities. These studies laid the groundwork for subsequent research in probabilistic modeling of tennis outcomes.

Kovalchik (2016) \[5\] conducted a comparison of 11 published tennis prediction models, categorizing them into three classes: point-based models relying on the iid assumption, regression-based models, and paired comparison models. The study found that point-based models had lower accuracy and higher log loss, regression and paired comparison models generally outperformed them.

Furthermore, given the importance of player rankings and performance metrics in tennis prediction models, it is essential to understand the context provided by the ATP (Association of Tennis Professionals). This institution is the principal governing body of men's professional tennis. It oversees the ATP Tour, which features the highest level of men's tennis tournaments worldwide, including Grand Slams, Masters 1000 events, and other competitive circuits. The ATP rankings system, introduced in 1973, is used to evaluate and rank players based on their performance in sanctioned tournaments over a rolling 52-week period, serving as a critical metric for seedings and qualifications (ATP Tour, n.d.)[19].

Building on these studies, this research uses the Tennis ATP dataset (Sackmann, 2021) ) to investigate two specific questions:

1. How does the difference in player rankings influence the duration of a tennis match? 

2. How do the number of aces and the court surface type affect a player's odds of winning a match?

## Methods

### Data and preprocessing

The dataset used in this study is the Tennis ATP Dataset curated by Jeff Sackmann (2021) \[1\]. This dataset serves as a comprehensive repository of professional tennis data, encompassing a wide range of player information, historical rankings, match outcomes, and statistical metrics. This dataset serves as a valuable resource for analyzing trends and performance in professional tennis, forming the basis for addressing the research questions in this study.

The time frame selected includes ATP match data from 2014-2024, the subsets chosen are challenger matches and professional and tournament class A matches such as Davis Cup, Roland Garros and others. The records from this period consist in 116,103 matches where each match has 49 variables. 

Pertaining the first research question, to assess the effect of factors on the match length, the difference in the number of aces, rankings, and ranking points between the winner and loser were calculated. These perfomance metrics aim to provide more tangible and interpretable predictors for the model by focusing on measurable aspects of the players performance. Grouping variables into performance metrics also helps to frame the analysis in a way that aligns with the context of the sport and makes the regressors more meaningful and insightful.

To address the issue of missing values, a multiple imputation approach was applied using the mice package. This method generates several imputed datasets to account for the uncertainty inherent in estimating missing values, thereby enhancing the robustness of subsequent analyses. Predictive mean matching (PMM) was employed as the imputation technique, combining regression-based prediction with donor-based imputation. This ensures that imputed values align with the observed data distribution, remaining realistic and within plausible ranges.

In respect to the second research question, which focuses on analyzing match outcomes, additional data processing steps were taken. The original dataset, which contains match-level features with information on both the winner and loser in a single record, was restructured. This transformation reorganized the data at the player level, ensuring that each record represents either a win or a loss for a given player. The dimensions for this transformed dataset are 218321 records and 30 variables. This adjustment allows for a more focused analysis of the factors influencing match outcomes.

For the second research question, 4,739 records (2%) with missing values in the aces column were excluded. This decision was based on the observation that missing data in aces systematically coincided with missing values for all other match statistics. A similar approach was applied to the serving games variable 4,740 records (2%), as its missing data also indicated the absence of other critical match details, further supporting exclusion. For the remaining variables without systematic missingness, a multiple imputation technique was applied, informed by the results of the imputation method used in the first research question.

### Variable selection

Taking as reference previous research regarding the most relevant features involved in the outcome of a tennis match (Newton et al., 2005\[1\]; O'Malley 2008\[2\]; Kovalchik, 2016) a pre selection was made observing the limitation of the available data. In order to further refine the process of feature selection exploratory data analysis was conducted using correlation plots, box plots and scatterplots.

### Model fitting and evaluation

# Pending

In regard of the first research questions, linear regression was used to model the relationship between the differences between ranking and acess. How does the difference in player rankings influence the duration of a tennis match?

linear regression to evaluate inference capabilities and determining the principal factors for a match win using logistic regression to evaluate the probability of a win. Variance Inflation Factor (VIF) was used to test multi-colinearity. For the linear regression task the assumptions for the model are tested via residual vs fitted plots and normal q-q plots, furthermore, the performance of the model is evaluated using the adjusted r squared metric. In terms of logistic regression, accuracy, recall sensitivity and specificity are used to evaluate the model. Lasso Regularization is implemented to prevent overfitting of the model due to too many variables. The AIC score is also used to evaluate the model, incorporating the number of predictors into the overall score. 
# Pending


## Results

```{r load-packages, message = FALSE, warning = FALSE, echo = FALSE}
library(tidyverse)
library(dplyr)
library(tidyverse)
library(Hmisc)
library(cowplot)
library(corrplot)
library(ggplot2)
library(modelsummary)
library(car)
library(knitr)
library(conflicted)
library(glmnet)
conflict_prefer("filter", "dplyr")
```

```{r data-1, warning=FALSE, echo=FALSE, include=FALSE, results = 'hide'}
# Define the base URL for each type of match data
base_urls <- list(
  qualy_chall = "https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_qual_chall_",
  #futures = "https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_futures_",
  match = "https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_"
)

# Get the current year and create a sequence for the last 5 years
years <- (as.numeric(format(Sys.Date(), "%Y")) - 10):as.numeric(format(Sys.Date(), "%Y"))

# Create a function to download and combine data for all years and match types
download_data <- function(base_url, years) {
  data_list <- lapply(years, function(year) {
    url <- paste0(base_url, year, ".csv")
    tryCatch(
      read.csv(url),
      error = function(e) {
        message("Failed to download: ", url)
        NULL
      }
    )
  })
  # Combine all years into a single data frame
  do.call(rbind, data_list)
}

# Download and combine data for each match type
tennis_qualy_chall <- download_data(base_urls$qualy_chall, years)
#tennis_futures <- download_data(base_urls$futures, years)
tennis_match <- download_data(base_urls$match, years)

# Define a function to standardize column types
standardize_columns <- function(df) {
  df %>%
    mutate(
      tourney_level = as.character(tourney_level),
      winner_seed = as.character(winner_seed),
      loser_seed = as.character(loser_seed)
      ) 
}

# Apply the function to each dataset
tennis_qualy_chall <- standardize_columns(tennis_qualy_chall)
tennis_match <- standardize_columns(tennis_match)

# Combine all datasets
tennis <- bind_rows(tennis_qualy_chall,tennis_match) #tennis_futures,

tennis <- tennis %>%
  mutate(
    winner_hand = case_when(
      winner_hand == "" | winner_hand == "U" ~ "A",  # Convert "" or "U" to "A" for winner
      TRUE ~ winner_hand  # Keep the original value for other cases
    ),
    loser_hand = case_when(
      loser_hand == "" | loser_hand == "U" ~ "A",  # Convert "" or "U" to "A" for loser
      TRUE ~ loser_hand  # Keep the original value for other cases
    )
  )
tourney_mapping <- c("D" = 0, "C" = 1, "A" = 2, "M" = 3, "G" = 4, "F" = 5)
tennis$tourney_level_ord <- as.numeric(tourney_mapping[tennis$tourney_level])
tennis$w_bpSave_ratio <- tennis$w_bpSaved / tennis$w_bpFaced
tennis$l_bpSave_ratio <- tennis$l_bpSaved / tennis$l_bpFaced

# View the combined dataset
head(tennis)
dim(tennis)
sum(is.na(tennis$minutes))
tennis <- tennis %>%
  filter(!is.na(minutes) & minutes>0)

# Subset the rows where winner_ht is NA
#missing_height_players <- tennis %>%
  #filter(is.na(winner_ht)) %>%
  #distinct(winner_name)
#table(tennis$winner_hand)
```

```{r , message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, results = 'hide'}
# Create a long-format dataset for both winners and losers
tennis_long <- tennis %>%
  filter(!is.na(minutes) & !is.na(winner_rank) & !is.na(loser_rank))%>%
  mutate(
    win = 1,
    player_id = winner_id,
    player_name = winner_name,
    player_seed = winner_seed,
    player_entry = winner_entry,
    player_hand = winner_hand,
    player_ht = winner_ht,
    player_ioc = winner_ioc,
    player_age = winner_age,
    aces = w_ace,
    df = w_df,
    svpt = w_svpt,
    first_in = w_1stIn,
    first_won = w_1stWon,
    second_won = w_2ndWon,
    svgms = w_SvGms,
    bp_saved = w_bpSaved,
    bp_faced = w_bpFaced,
    rank = winner_rank,
    rank_points = winner_rank_points,
    score = score,
    tourney_id = tourney_id,
    tourney_name = tourney_name,
    surface = surface,
    draw_size = draw_size,
    tourney_level = tourney_level,
    tourney_date = tourney_date,
    match_num = match_num
  ) %>%
  select(
    tourney_id, tourney_name, surface, draw_size, tourney_level, tourney_date,
    match_num, player_id, player_seed, player_entry, player_name, player_hand,
    player_ht, player_ioc, player_age, score, rank, rank_points, aces, df, svpt,
    first_in, first_won, second_won, svgms, bp_saved, bp_faced, win
  ) %>%
  bind_rows(
    # Create rows for the loser
    tennis %>%
      mutate(
        win = 0,
        player_id = loser_id,
        player_name = loser_name,
        player_seed = loser_seed,
        player_entry = loser_entry,
        player_hand = loser_hand,
        player_ht = loser_ht,
        player_ioc = loser_ioc,
        player_age = loser_age,
        aces = l_ace,
        df = l_df,
        svpt = l_svpt,
        first_in = l_1stIn,
        first_won = l_1stWon,
        second_won = l_2ndWon,
        svgms = l_SvGms,
        bp_saved = l_bpSaved,
        bp_faced = l_bpFaced,
        rank = loser_rank,
        rank_points = loser_rank_points,
        score = score,
        tourney_id = tourney_id,
        tourney_name = tourney_name,
        surface = surface,
        draw_size = draw_size,
        tourney_level = tourney_level,
        tourney_date = tourney_date,
        match_num = match_num
      ) %>%
      select(
        tourney_id, tourney_name, surface, draw_size, tourney_level, tourney_date,
        match_num, player_id, player_seed, player_entry, player_name, player_hand,
        player_ht, player_ioc, player_age, score, rank, rank_points, aces, df, svpt,
        first_in, first_won, second_won, svgms, bp_saved, bp_faced, win
      )
  )

# Create new columns for year, month, and day
tennis_long <- tennis_long %>%
  mutate(
    match_year = substr(tourney_date, 1, 4),       # Extract the first 4 characters as the year
    match_month = substr(tourney_date, 5, 6)     # Extract the 5th and 6th characters as the month
)

tennis_long <- tennis_long %>%
  rename(
    player_height = player_ht,
    double_faults = df,
    player_country = player_ioc,
    serve_points = svpt,
    first_serves=first_in,
    first_serves_points_won=first_won,
    second_serves_points_won=second_won,
    serve_games=svgms,
    break_points_saved=bp_saved,
    break_points_faced=bp_faced
  )

# Convert Win to a factor with appropriate labels
tennis_long <- tennis_long |>
  mutate(
    win = factor(win, levels = c(0, 1), labels = c("Loss", "Win")),
    rank = if_else(is.na(rank), 0, rank),
    rank_points = if_else(is.na(rank_points), 0, rank_points)
  )

tennis_long <- tennis_long %>%
  filter(!is.na(aces) & !is.na(player_age) & !is.na(serve_games))

# Get the number of NAs in each column
#na_count <- sapply(tennis_long, function(x) sum(is.na(x)))
# Display the result
#na_count
#dim(tennis_long)
#tennis_long %>% 
#202

sum(is.na(tennis_long$player_height))

sum(is.na(tennis_long$serve_games))
sum(is.na(tennis_long$draw_size))
```

### Overview of key variables of interest

```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, results = 'hide'}
tennis_long %>%
  group_by(win) %>%
  dplyr::summarize(count = n())

tennis %>%
  group_by(surface) %>%
  dplyr::summarize(count = n(), proportion = n()/116050)

```
The dataset has a fairly even distribution of players that Win (101746) and Lose (111621), implying that there would not be more information gain in one outcome over the other. The surface types do not have as balanced of a distribution. Majority of the matches are played on a Hard or Clay surface, accounting for 53.5% and 41.1% of the matches. About 5% of the matches are played on Grass and only 0.2% on Carpet.
Below we consider the distribution of the key continuous variables:

# Pending

```{r warning=FALSE, echo=FALSE}
summary_table <- data.frame(
  Variable = c("minutes", "rank", "aces"),
  Minimum = c(min(tennis_long$minutes, na.rm = TRUE), min(tennis_long$rank, na.rm = TRUE), min(tennis_long$aces, na.rm = TRUE)),
  `Quantile 1` = c(quantile(tennis_long$minutes, 0.25, na.rm = TRUE), quantile(tennis_long$rank, 0.25, na.rm = TRUE), quantile(tennis_long$aces, 0.25, na.rm = TRUE)),
  Mean = c(mean(tennis$minutes, na.rm = TRUE), mean(tennis_long$rank, na.rm = TRUE), mean(tennis_long$aces, na.rm = TRUE)),
  Median = c(median(tennis$minutes, na.rm = TRUE), median(tennis_long$rank, na.rm = TRUE), median(tennis_long$aces, na.rm = TRUE)),
  `Quantile 3` = c(quantile(tennis$minutes, 0.75, na.rm = TRUE), quantile(tennis_long$rank, 0.75, na.rm = TRUE), quantile(tennis_long$aces, 0.75, na.rm = TRUE)),
  Maximum = c(max(tennis$minutes, na.rm = TRUE), max(tennis_long$rank, na.rm = TRUE), max(tennis_long$aces, na.rm = TRUE))
)

kable(summary_table, caption = "Summary Statistics for Variables")
```
# Pending


### **Research question 1: Effects of the difference in ranking over the length in minutes for a tennis match**

```{r, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, results = 'hide'}
# Count the number of NAs in each column
missing_summary <- tennis  %>%
  summarise(across(everything(), ~ sum(is.na(.))))
missing_summary

# Summary statistics of the variables
summary(tennis)

# Creating new binary indicators
tennis <- tennis %>%
  mutate(
    winner_seeded = ifelse(is.na(winner_seed), 0, 1),
    loser_seeded = ifelse(is.na(loser_seed), 0, 1)
  )

# Group-wise imputation: ensure that replacements respect the context of the surface variable
#tennis <- tennis %>%
#  group_by(surface) %>%
#  mutate(
#    winner_ht = ifelse(is.na(winner_ht), mean(winner_ht, na.rm = TRUE), winner_ht),
#    loser_ht = ifelse(is.na(loser_ht), mean(loser_ht, na.rm = TRUE), loser_ht),
#    minutes = ifelse(is.na(minutes), median(minutes, na.rm = TRUE), minutes)
#  ) %>%
#  ungroup()

# Drop the missing values in our target variable
#tennis <- tennis %>% filter(!is.na(minutes))

# Calculate the percentage of missing values in rank_diff
percent_missing_minutes<- sum(is.na(tennis$minutes)) / nrow(tennis) * 100
# Print the result
print(percent_missing_minutes)

# Player Performance Metrics: Create performance difference metrics (e.g., difference in aces, rank, and rank points):
tennis <- tennis %>%
  mutate(
    diff_aces = abs(w_ace - l_ace),
    diff_rank = abs(loser_rank - winner_rank),
    diff_rank_points = abs(loser_rank_points - winner_rank_points)
  )

# Categorical Variables: Convert categorical variables like surface and tourney_level to factors:
tennis <- tennis %>%
  mutate(
    surface = as.factor(surface),
    tourney_level = as.factor(tourney_level)
  )
# Cap or remove extreme values in minutes, winner_ht, and loser_ht:
tennis <- tennis %>%
  mutate(
    minutes = ifelse(minutes > 300, 300, minutes),
    winner_ht = ifelse(winner_ht > 210, 210, winner_ht),
    loser_ht = ifelse(loser_ht > 210, 210, loser_ht)
  )

#winner_seed
#loser_seed

#15720
```

> Below is the linear regression analyzing the relationshiop between minutes and a multitude of regressors

The second regression model was designed to address the low explanatory power of the initial model, which had a low adjusted R². By incorporating additional predictors such as player performance metrics, tournament levels, and specific match characteristics, the aim was to better capture the complexity of factors affecting match duration (minutes). This approach improved the adjusted R² = 0.57, suggesting that these added variables account for more of the variance in the response variable. The model also includes an interaction term and accounts for more detailed match-level attributes, providing a more comprehensive view of the factors influencing match length.

Some variables that significantly impact match duration (minutes) include the difference in rank between players, which shows a strong negative association, indicating that matches with greater rank disparity are shorter. The number of breakpoints saved by the winner has a significant positive effect, suggesting that matches where the winner saves more breakpoints tend to last longer. Lastly, the difference in aces between players negatively affects match duration, with matches showing a greater disparity in aces being resolved more quickly. These variables emphasize the importance of player performance and competitive dynamics in determining match length.


```{r, message = FALSE, warning=FALSE, echo=FALSE}
#imputation
library(mice)
library(sjlabelled)
library(tidyverse)
# Exclude columns and check data
tennis$surface <- factor(tennis$surface, levels = c("Carpet", "Clay", "Grass", "Hard"))
tennis$surface <- relevel(tennis$surface, ref = "Carpet")
tennis.sub <- tennis %>%
  select(minutes , diff_rank , diff_aces , winner_ht , loser_ht , surface , 
            tourney_level_ord, tourney_level , winner_age , loser_age , w_df , l_df , 
            w_bpSave_ratio , l_bpSave_ratio)  # Exclude irrelevant columns

tennis.sub <- unlabel(tennis.sub) #unlabel the data (labels cause problem for the mice function)
tennis.imp <- mice(tennis.sub, m=5, method="pmm", print=FALSE, seed = 123)
tennis.comp <- complete(tennis.imp, "long", include=TRUE) #stack the imputed values into one variable and include he observed values
tennis.comp$winner_ht.comp <- cci(tennis$winner_ht) #create an indicator for completeness

ggplot(tennis.comp, aes(x=factor(.imp), y=winner_ht, fill=winner_ht.comp))+
  geom_boxplot()

imp.mods <- with(tennis.imp, lm(minutes ~ diff_rank*tourney_level + diff_aces + winner_ht + loser_ht + 
            surface + winner_age + loser_age + w_df + l_df + 
             w_bpSave_ratio + l_bpSave_ratio))
summary(pool(imp.mods))
```
```{r}
# Extract coefficients, p-values, and standard errors
coef_summary <- summary(pool(imp.mods))

# Get the coefficients, standard errors, and p-values
terms <- coef_summary$term
coefficients <- as.numeric(coef_summary$estimate)
standard_errors <- as.numeric(coef_summary$std.error)
p_values <- as.numeric(coef_summary$p.value)

# Create a data frame to organize the results
coeff_df <- data.frame(
  term = terms,
  coefficient = coefficients,
  p_value = p_values,
  stringsAsFactors = FALSE
)

# Display the table with kable
colnames(coeff_df) <- c("Variable", "Coefficient", "P-value")
kable(coeff_df, caption = "Linear Regression Coefficients and P-values")
```

> Below is the diagnostic plot for the second linear model. 

```{r, fig.width=9, fig.height=10}
par(mfrow = c(2,2))

# Pool the results of the imputed models
pooled_model <- pool(imp.mods)

# Extract residuals and fitted values from each imputed model
residuals_list <- lapply(1:5, function(i) {
  model <- with(complete(tennis.imp, i), lm(minutes ~ diff_rank*tourney_level + diff_aces + winner_ht + loser_ht + 
            surface + winner_age + loser_age + w_df + l_df + 
             w_bpSave_ratio + l_bpSave_ratio))
  data.frame(
    residuals = residuals(model),
    fitted = fitted(model),
    imputation = i
  )
})

# Combine the residuals and fitted values
residuals_combined <- do.call(rbind, residuals_list)

# Create diagnostic plots using ggplot2
ggplot(residuals_combined, aes(x = fitted, y = residuals, color = factor(imputation))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
  theme_minimal()

ggplot(residuals_combined, aes(sample = residuals, color = factor(imputation))) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Normal Q-Q Plot", x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal()
```
```{r}
# try with log transformed minutes
# for (i in 1:5) {
#   tennis.imp$imp$minutes[[i]] <- ifelse(tennis.imp$imp$minutes[[i]] == 0, 0.1, tennis.imp$imp$minutes[[i]])
# }
imp.log_mods <- with(tennis.imp, lm(log(minutes) ~ diff_rank*tourney_level + diff_aces + winner_ht + loser_ht + 
            surface + winner_age + loser_age + w_df + l_df + 
             w_bpSave_ratio + l_bpSave_ratio))
summary(pool(imp.log_mods))
```

```{r}
par(mfrow = c(2,2))

# Pool the results of the imputed models
pooled_model <- pool(imp.log_mods)

# Extract residuals and fitted values from each imputed model
residuals_list <- lapply(1:5, function(i) {
  model <- with(complete(tennis.imp, i), lm(log(minutes) ~ diff_rank*tourney_level + diff_aces + winner_ht + loser_ht + 
            surface + winner_age + loser_age + w_df + l_df + 
             w_bpSave_ratio + l_bpSave_ratio))
  data.frame(
    residuals = residuals(model),
    fitted = fitted(model),
    imputation = i
  )
})

# Combine the residuals and fitted values
residuals_combined <- do.call(rbind, residuals_list)

# Create diagnostic plots using ggplot2
ggplot(residuals_combined, aes(x = fitted, y = residuals, color = factor(imputation))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
  theme_minimal()

ggplot(residuals_combined, aes(sample = residuals, color = factor(imputation))) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Normal Q-Q Plot", x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal()
```
Despite achieving a higher adjusted R² compared to the first model, several key assumptions of the linear regression model appear to be violated. The "Residuals vs Fitted" plot indicates potential non-linearity in the relationships between predictors and the response variable, suggesting the model may not be capturing all relevant patterns. The "Q-Q Residuals" plot shows significant deviations from normality, particularly in the tails, which could compromise the reliability of hypothesis tests and confidence intervals. Additionally, the "Scale-Location" plot reveals heteroscedasticity, with residuals showing increasing variance as fitted values grow. While the larger R²suggests the model explains more variance in match duration, these assumption violations indicate that the results may not be entirely valid or interpretable under the linear regression framework, reducing the model's overall reliability. These violations suggest that the model might require transformations, interaction terms, or alternative regression methods to better satisfy these assumptions.


### **Research question 2: Aces and court surface type influence in match outcome**

```{r message = FALSE, warning=FALSE, echo=FALSE, include=FALSE, results = 'hide'}
conflicts_prefer(dplyr::summarize)
# Convert tourney level to ordinal variable:
  ## 0 = D (Davis Cup): Team competition, often less prestigious on an individual level.
  ## 1 = C (Challengers): Lower-tier tournaments below the main ATP Tour.
  ## 2 = A (Tour-Level Events): Regular ATP events not part of Masters 1000s, Grand Slams, or Finals.
  ## 3 = M (Masters 1000s): High-prestige, top-tier ATP tournaments after Grand Slams.  
  ## 4 = G (Grand Slams): The most prestigious tournaments in tennis (Australian Open, French Open, Wimbledon, US Open).
  ## 5 = F (Tour Finals and Other Season-Ending Events): Exclusive tournaments like the ATP Finals, featuring only the top-ranked players of the season.

tourney_mapping <- c("D" = 0, "C" = 1, "A" = 2, "M" = 3, "G" = 4, "F" = 5)
tennis_long$tourney_level_ord <- as.numeric(tourney_mapping[tennis_long$tourney_level])

# Use VIF to assess multicollinearity amongst all viable variables

  # 1. Create a model with no interaction terms and all viable variables
tennis_mod_no_interaction <- glm(win ~ draw_size + tourney_level_ord + player_hand + player_height +  player_age + rank + rank_points + double_faults + serve_points + first_serves + first_serves_points_won + second_serves_points_won + break_points_saved + break_points_faced + aces + surface,
               data=tennis_long,
               family="binomial")
vif(tennis_mod_no_interaction)
  # 1.1. Results: High VIF score for serve_points, first_serves, first_serves_points_won, second_serves_points_won, break_points_saved, break_points_faced. 

  # 1.2. Combine/create ratios
tennis_long$first_serve_win_ratio = tennis_long$first_serves_points_won/tennis_long$serve_points
tennis_long$second_serve_win_ratio = tennis_long$second_serves_points_won/(
  tennis_long$serve_points - tennis_long$first_serves)
tennis_long$break_pt_save_ratio = tennis_long$break_points_saved/tennis_long$break_points_faced
  ##tennis[71196,] l_ serve counts do not make sense. Remove that column from tennis_long
tennis_long <- tennis_long[!is.infinite(tennis_long$second_serve_win_ratio), ]

  # 2. Calculate VIF for new variables
mod_new_var <- glm(win ~ draw_size + tourney_level_ord + player_hand + player_height +  player_age + rank + rank_points + double_faults + first_serve_win_ratio + second_serve_win_ratio + break_pt_save_ratio + aces + surface,
               data=tennis_long,
               family="binomial")
vif(mod_new_var)
  # 2.1. RESULTS: draw_size and tourney_level_ord have high VIF scores
tennis_long %>%
  group_by(tourney_level_ord) %>% 
  summarize(mean = mean(draw_size), min = min(draw_size), max = max(draw_size))

  # 2.2. Remove tourney_level as more granular info comes from draw_size

  # 3. Final model
mod_limit <- glm(win ~ draw_size + player_hand + player_height +  player_age + rank + rank_points  + double_faults + first_serve_win_ratio + second_serve_win_ratio + break_pt_save_ratio + aces + surface, data=tennis_long, family="binomial")
vif(mod_limit)

tennis_long %>%
  group_by(tourney_level_ord) %>%
  summarize(mean = mean(draw_size), min = min(draw_size), max = max(draw_size))
```

To structure this model the relevand variables in related literature as well as the variables of interes along with the interaction term of the type of surface were included. To evaluate multicollinearity, the VIF score was used on an initial logistic regression model including all the variables selected. The raw variables representing a player's total serve points, number of first serve points made, number of first serve points won, number of second serve points won, number of break points faced, number of break points saved, total draw size in the tournament and the tournament level were all highly correlated. It was found that total number of serves attempted, first serves attempted, first serve points won and second serve points one were highly correlated with VIF scores ranging from 9 to 72.

To continue to capture this information, but limit multicollinearity, we combine these into the total first serve points won ratio which is a ratio of the total first serve points won to the total first serves attempted. Similarly, the total second serve points won ratio is the ratio of the total second serve points won to the difference between the total serves attempted and the total first serves attempted. The new VIF scores for these two ratios were less than 1.3 Similarly, the break points saved ratio is used in place of the overall counts. Lastly, between draw size and tournament level, draw size is only used as there is more granular information derived from draw size than tournament level.

```{r message = FALSE, warning=FALSE, echo=FALSE, include=FALSE, results = 'hide'}
# Model based on above identified columns and lasso regularization to limit variables and prevent overfitting:

#tennis_long_clean <- tennis_long[complete.cases(tennis_long[, c("win", "draw_size", "player_hand", "player_height", 
#                                                               "player_age", "rank", "rank_points", "double_faults", 
#                                                               "first_serve_win_ratio", "second_serve_win_ratio", 
#                                                              "break_pt_save_ratio", "aces", "surface")]), ]

tennis_long_clean <- tennis_long[, c("win", "draw_size", "player_hand", "player_height", 
                                                               "player_age", "rank", "rank_points", "double_faults", 
                                                               "first_serve_win_ratio", "second_serve_win_ratio", 
                                                              "break_pt_save_ratio", "aces", "surface")]#), ]

formula = win ~ draw_size + player_hand+ player_height +  player_age + rank + rank_points + aces*surface  + double_faults + first_serve_win_ratio + second_serve_win_ratio + break_pt_save_ratio

# Recreate the design matrix and target variable with the cleaned data
X <- model.matrix(formula, data = tennis_long_clean)[, -1]  # Remove the intercept column
y <- tennis_long_clean$win

# Fit the logistic regression model with Lasso regularization using glmnet
#lasso_model <- glmnet(X, y, family = "binomial", alpha = 1)

# Print the model details
#print(lasso_model)

# You can use cv.glmnet for cross-validation to find the best lambda
#cv_lasso_model <- cv.glmnet(X, y, family = "binomial", alpha = 1)

# Plot the cross-validation results
#plot(cv_lasso_model)

# Get the best lambda (the optimal penalty)
#best_lambda <- cv_lasso_model$lambda.min
#print(best_lambda)

# Fit the model using the best lambda
#final_lasso_model <- glmnet(X, y, family = "binomial", alpha = 1, lambda = best_lambda)

# Print final model coefficients
#print(coef(final_lasso_model))
```

Mentioned in the methodology section of this document, a multiple imputation technique with the mice package was applied to handle non systematic missing data correspondent to the variable height. Presented below is a summary of the final logistic regression model:

```{r}
#inputation
library(mice)
library(sjlabelled)
library(tidyverse)
# Exclude columns and check data
tennis_long.sub <- tennis_long_clean %>%
  select(win, draw_size , player_hand,  player_height,  player_age, rank, rank_points, aces, surface, double_faults, break_pt_save_ratio)  # Exclude irrelevant columns
tennis_long.sub$player_hand <- as.factor(tennis_long.sub$player_hand)
tennis_long.sub$surface <- as.factor(tennis_long.sub$surface)

tennis_long.sub <- unlabel(tennis_long.sub) #unlabel the data (labels cause problem for the mice function)
tennis_long.imp <- mice(tennis_long.sub, m=5, method="pmm", print=FALSE, seed = 123)
tennis_long.comp <- complete(tennis_long.imp, "long", include=TRUE) #stack the imputed values into one variable and include the observed values
tennis_long.comp$player_height.comp <- cci(tennis_long_clean$player_height) #create an indicator for completeness

ggplot(tennis_long.comp, aes(x=factor(.imp), y=player_height, fill=player_height.comp))+
  geom_boxplot()

imp.mods_long <- with(tennis_long.imp, glm(win ~ draw_size + player_hand+ player_height +  player_age + rank + rank_points + aces*surface  + double_faults + break_pt_save_ratio,
               family="binomial"))

coef_summary <- summary(pool(imp.mods_long))

# Extract key information for the table
coefficients <- coef_summary$estimate
std_errors <- coef_summary$std.error
exp_coefficients <- exp(coefficients)  # Calculate odds ratios
lower_ci <- exp(coefficients - 1.96 * std_errors)  # Lower bound of 95% CI
upper_ci <- exp(coefficients + 1.96 * std_errors)  # Upper bound of 95% CI
p_values <- coef_summary$p.value

# Create a data frame to organize the results
coeff_df <- data.frame(
  term = coef_summary$term,
  coefficient = round(coefficients, 2),
  exp_coefficient = round(exp_coefficients, 2),
  lower_ci = round(lower_ci, 2),
  upper_ci = round(upper_ci, 2),
  p_value = round(p_values, 2),
  stringsAsFactors = FALSE
)

# Format and display the table using kable
colnames(coeff_df) <- c("Variable", "Coefficient", "Odds Ratio", "Lower 95% CI", "Upper 95% CI", "P-value")
kable(coeff_df, caption = "Logistic Regression Coefficients, Odds Ratios, Confidence Intervals, and P-values")

```

Analyzing the variables of interest aces and surface, holding every other variable constant, applying exponential we have an effect of 1.1 times increase in odds of winning for every extra ace point. Similarly matches on Clay and Hard surfaces increase the odds of winning in comparison to playing on a Carpet by 2.1 and 1.7 times respectively. Surprisingly, the impact of every extra ace point is not statistically significant between the different surface types. Another statistically significant variable impacting the odds of winning is the right vs left-handed stature of the player. Specifically being Right or Left Handed (as opposed to undefined) is associated with approximately 9.7 times increase in odds of winning.

```{r , message=FALSE, warning=FALSE}

# Load necessary libraries
library(mice)
library(sjlabelled)
library(tidyverse)
library(caret)    # For confusionMatrix
library(knitr)    # For kable
library(kableExtra)
# Load necessary libraries
library(pROC)
library(ggplot2)
# Generate predictions for each imputed dataset
pred_probs <- complete(tennis_long.imp, "all") %>%
  lapply(function(data) {
    glm_model <- glm(win ~ draw_size + player_hand + player_height + player_age + 
                       rank + rank_points + aces * surface + double_faults + break_pt_save_ratio,
                     family = "binomial", data = data)
    predict(glm_model, newdata = data, type = "response")
  })

# Aggregate predictions by averaging across imputations
mean_pred_probs <- Reduce("+", pred_probs) / length(pred_probs)

# Step 3: Compute ROC and AUC using original win labels
roc_curve <- roc(tennis_long_clean$win, mean_pred_probs)

# Step 4: Plot the ROC curve
roc_data <- data.frame(
  FPR = 1 - roc_curve$specificities,
  TPR = roc_curve$sensitivities
)

auc_value <- auc(roc_curve)
auc_text <- paste("AUC:", round(auc_value, 2))

ggplot(roc_data, aes(x = FPR, y = TPR)) +
  geom_line(color = "blue", size = 1) +
  geom_abline(linetype = "dashed", color = "red") +
  annotate("text", x = 0.6, y = 0.2, label = auc_text, size = 5, color = "black") +
  labs(title = "ROC Curve", x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal()

```


```{r message = FALSE, warning=FALSE, echo=FALSE, include=FALSE, results = 'hide'}
# Load necessary libraries
library(caret)    # For confusionMatrix
library(knitr)    # For kable
library(kableExtra)
# Generate predictions
pred_probs <- predict(pool(imp.mods_long), type = "response")
pred_binary <- ifelse(pred_probs > 0.5, 1, 0)
pred_binary <- factor(pred_binary, levels = c(0, 1), labels = c("Loss", "Win"))

# Create a confusion matrix
conf_matrix <- confusionMatrix(pred_binary, tennis_long_clean$win)

conf_matrix_table <- conf_matrix$table
conf_matrix_df <- as.data.frame.matrix(conf_matrix_table)
#conf_matrix_df <- cbind(Actual = rownames(conf_matrix_df), conf_matrix_df)
conf_matrix_latex <- conf_matrix_df %>%
  kable("latex", booktabs = TRUE, 
        caption = "Confusion Matrix: Actual vs. Predicted Satisfaction",
        align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position"))

# Extract and prepare the metrics for display
metrics <- data.frame(
  Metric = c("Accuracy", "Precision", "Recall", "F1 Score", "Specificity", "Sensitivity", "Positive Predictive Value", "Negative Predictive Value"),
  Value = c(
    conf_matrix$overall['Accuracy'],
    conf_matrix$byClass['Pos Pred Value'],
    conf_matrix$byClass['Sensitivity'],
    conf_matrix$byClass['F1'],
    conf_matrix$byClass['Specificity'],
    conf_matrix$byClass['Sensitivity'],
    conf_matrix$byClass['Pos Pred Value'],
    conf_matrix$byClass['Neg Pred Value']
  )
)

# Display the metrics using kable
#cat("\nMetrics:\n")
kable(metrics, format = "markdown", col.names = c("Metric", "Value"))
```

The performance of the logistic regression model was evaluated using standard classification metrics, including accuracy, precision, recall, and F1 score. The model achieved an accuracy of 0.8117, indicating that approximately 81.17% of predictions matched the true outcomes. The precision of the model was 0.8230, reflecting its ability to correctly identify positive cases while minimizing false positives. The recall was measured at 0.8155, demonstrating the model's capability to correctly identify a high proportion of actual positive cases. Finally, the F1 score, a harmonic mean of precision and recall, was calculated to be 0.8192, indicating a balanced performance between these two metrics. Together, these results suggest the model performs reliably in predicting match outcomes based on the given features.
```{r}

ggplot(tennis_long_clean, aes(x = win, y = aces, fill = surface)) +
  geom_boxplot() +
  scale_fill_manual(values = c("Clay" = "brown", "Grass" = "green", "Hard" = "blue")) +
  labs(
    title = "Distribution of Aces for Winners vs Losers by Surface",
    x = "Match Outcome",
    y = "Number of Aces",
    fill = "Surface"
  ) +
  theme_minimal() +
  theme(legend.position = "right")


```
The distribution of aces played by Winners is slightly higher valued than the distribution of aces by Losers. This supports the model estimates and the slight increase in odds of winning (by 1.1 times) for every additional ace played.

## Conclusion

In conclusion, our analysis for identifying key factors significantly influencing match duration, including rank differences, aces, player heights, the type of surface of the field, age, breakpoints and tournament-level details. By expanding the model to include these variables, we improved the explanatory power (adjusted R²), highlighting their importance in predicting match length. However, residual diagnostics revealed violations of assumptions, indicating limitations in the linear regression approach for capturing complex relationships in the data. These findings emphasize the value of significant predictors while suggesting the need for alternative models to better address the data's complexity

Overall, while every additional ace does improve the probability of a player winning, this factor does not have a heavy impact. Further, some surfaces like clay, significantly improve the chances of winning; however, these two variables are not highly interactive. More realistically, in a match both players will be on the same surface level, so this factor does not help one player over another. Since the model only reached an F-score of 72.5, it appears as though there may be other more indicitave factors of which player will win. 


## References

\[1\] Sackmann, J. (n.d.). Tennis databases, files, and algorithms \[Data set\]. Tennis Abstract. Licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Based on a work at https://github.com/JeffSackmann.

\[2\] Newton, P. K., & Keller, J. B. (2005). Probability of winning at tennis I. Theory and data. Studies in applied Mathematics, 114(3), 241-269.

\[3\] O'Malley, A. J. (2008). Probability formulas and statistical analysis in tennis. Journal of Quantitative Analysis in Sports, 4(2).

\[4\] Riddle, L. H. (1988). Probability models for tennis scoring systems. Journal of the Royal Statistical Society Series C: Applied Statistics, 37(1), 63-75.

\[5\] Kovalchik, S. A. (2016). Searching for the GOAT of tennis win prediction. Journal of Quantitative Analysis in Sports, 12(3), 127-138.

\[6\] Štrumbelj, E., & Vračar, P. (2012). Simulating a basketball match with a homogeneous Markov model and forecasting the outcome. International Journal of Forecasting, 28(2), 532-542.

\[7\] Boulier, B. L., & Stekler, H. O. (1999). Are sports seedings good predictors?: an evaluation. International Journal of Forecasting, 15(1), 83-91.

\[8\] Lasek, J., Szlávik, Z., & Bhulai, S. (2013). The predictive power of ranking systems in association football. International Journal of Applied Pattern Recognition, 1(1), 27-46.

\[9\] Sklenička, J. (2024). Predicting the outcomes of tennis matches. How important is the factor of different surfaces?.

[15] Boulier, B. L., & Stekler, H. O. (1999). Are sports seedings good predictors?: an evaluation. International Journal of Forecasting, 15(1), 83-91.

[16] Klaassen, F. J., & Magnus, J. R. (2003). Forecasting the winner of a tennis match. European Journal of Operational Research, 148(2), 257-267.

[17] Kovalchik, S. A. (2016). Searching for the GOAT of tennis win prediction. Journal of Quantitative Analysis in Sports, 12(3), 127-138.

[18] Foley-Train, J. (2014). Sports betting: Commercial and integrity issues. Report prepared for the Association of British Bookmakers, European Gaming and Betting Association, European Sport Security Association and Remote Gambling Association. Retrieved January, 21, 2015.

[19] ATP Tour. (n.d.). About the ATP. Retrieved from https://www.atptour.com